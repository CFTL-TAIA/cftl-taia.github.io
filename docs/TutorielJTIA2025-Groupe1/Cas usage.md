---
sidebar_position: 2
---

# Cas d'usage
Utilisation de l’IA pour l’Analyse de la Qualité des User Stories & la Génération des cas de tests

---
## Fiche d'identité du cas d'usage

**Auteurs** : Caroline Distriquin (CEA) - Florent Vaution (Ouest-France) - Jules Louail (Inetum) - Sarah Leroy (Kereval)  

**Relecteur** : Yann Helleboid (Orange) - Frédéric Assante Di Capillo (Sii) - Michael Granier (Nocode Testing)  

---
## Description du cas d'usage
Assistance par IA à l’analyse de la qualité des user stories selon des critères standardisés (INVEST, BABOK, IEEE830, IREB, etc.) dans un contexte Agile Scrum.

---
## Problématique(s) traitée(s) 
- Difficulté à garantir la qualité homogène des user stories rédigées par des équipes pluridisciplinaires.
- Risque de non-conformité aux standards d’écriture des exigences (INVEST, BABOK, etc.), entraînant des ambiguïtés, des oublis ou des user stories non testables.
- Charge de relecture et d’analyse manuelle importante pour les Product Owners, Scrum Masters et testeurs.

---
## Groupe d’activité de test ISTQB
- Analyse et conception des tests
- Gestion des exigences
- Assurance qualité des artefacts de test

---
## Types de tests
- Tests d’acceptation
- Tests fonctionnels
- Tests non fonctionnels
- Tests de validation des exigences

---
## Métier / Profil
- Développeurs
- Testeurs
- Managers de tests
- Product Owners
- Scrum Masters
- Ingénieur d’exigence

---
## Bénéfices attendus / constatés 
- Amélioration de la qualité et de la clarté des user stories
- Réduction du temps de revue et de correction des user stories
- Diminution des défauts liés à des exigences mal définies
- Accélération du cycle de développement grâce à des user stories prêtes à être développées et testées
- Standardisation de l’analyse grâce à l’application systématique de critères objectifs

---
## Evaluation du ROI (KPI) 
- Pourcentage de user stories conformes dès la première revue
- Nombre de corrections ou d’itérations nécessaires par user story
- Temps moyen de revue d’une user story
- Nombre de défauts détectés en phase de test liés à des exigences mal rédigées
- Satisfaction des équipes sur la qualité des user stories

---
## Risques
- Dépendance excessive à l’outil IA, au détriment de l’esprit critique humain
- Résultats biaisés si le prompt ou les critères sont mal paramétrés
- Difficulté d’adaptation aux contextes spécifiques ou aux exceptions métier
- Confidentialité des données si l’IA traite des user stories sensibles

---
## Ressources 
- Outil d’IA générative (type LLM)
- Modèles de prompts adaptés aux différents profils et critères
- Documentation des critères d’analyse (INVEST, BABOK, etc.)
  - ISTQB Syllabus – Chapitres sur la gestion des exigences et l’analyse des artefacts
  - BABOK (Business Analysis Body of Knowledge)
  - IEEE830 – Recommandations pour la rédaction des exigences
  - IREB (International Requirements Engineering Board)
  - Documentation Agile (Scrum Guide, guides sur INVEST, etc.)
- Guides de bonnes pratiques sur la rédaction des user stories

---
## Références

